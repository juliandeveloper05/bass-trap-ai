# ğŸµ Dumu â€” AI Bass Extraction

![Dumu](https://img.shields.io/badge/Dumu-v1.3.0-a3e635?style=flat-square) ![React](https://img.shields.io/badge/React_18-Vite_4-61DAFB?style=flat-square&logo=react) ![FastAPI](https://img.shields.io/badge/FastAPI-0.111-009688?style=flat-square&logo=fastapi) ![PyTorch](https://img.shields.io/badge/PyTorch-2.1_CPU-EE4C2C?style=flat-square&logo=pytorch) ![TensorFlow](https://img.shields.io/badge/TensorFlow-2.15-FF6F00?style=flat-square&logo=tensorflow) ![Docker](https://img.shields.io/badge/Docker-Containerized-2496ED?style=flat-square&logo=docker) ![License](https://img.shields.io/badge/License-MIT-green?style=flat-square)

> **Upload your track Â· Isolate the bass with AI Â· Export to MIDI.**

Dumu is a full-stack AI application that extracts the bass line from any audio file using **two neural networks** â€” Meta AI's **Demucs** for source separation and Spotify's **Basic Pitch** for audio-to-MIDI conversion â€” and delivers a playable MIDI file ready for your DAW.

ğŸ”— **Live:** [dumu.surge.sh](https://dumu.surge.sh)  
ğŸ”— **Live (Mirror):** [dumu.vercel.app](https://dumu.vercel.app)  
ğŸ”— **Backend API:** [julian4deep-bass-trap-ai.hf.space](https://julian4deep-bass-trap-ai.hf.space)

---

## âœ¨ What's New in v1.3.0

- âœ… **Neural network architecture visualization** â€” live canvas showing Demucs U-Net and Basic Pitch CNN with animated data particles flowing through layers
- âœ… **Fixed critical 503 errors** â€” restructured backend into proper Python packages (`api/`, `services/`)
- âœ… **Switched to `htdemucs`** â€” lighter model (~1.5 GB vs ~5 GB), prevents OOM on free tier
- âœ… **Forced CPU execution** â€” `--device cpu`, `-j 1`, 10-min timeout on Demucs subprocess
- âœ… **Added `/health` endpoint** â€” container health checks for HF Spaces Docker startup
- âœ… **Cleaned dependencies** â€” removed torch from `requirements.txt` (Dockerfile handles it), removed `diffq`, `email-validator`
- âœ… **Removed Railway/nixpacks artifacts** â€” HF Spaces Docker only, no more `Procfile`, `nixpacks.toml`, `railway.json`

---

## ğŸ§  AI & Machine Learning

| Model | Created by | Architecture | Purpose |
|---|---|---|---|
| **Demucs v4** (`htdemucs`) | Meta AI / Facebook Research | U-Net + Transformer | Source Separation â€” isolates bass from full mix |
| **Basic Pitch** | Spotify Research | CNN (Convolutional Neural Network) | Audio-to-MIDI â€” detects pitch, onset & notes |

Both models run inference on **CPU** using PyTorch and TensorFlow respectively. Processing a full-length track takes 3â€“7 minutes on CPU.

### Pipeline Architecture

```
Audio File (MP3/WAV/FLAC/OGG)
        â”‚
        â–¼
[1] BPM Detection      â€” Librosa beat_track() Â· DSP analysis
        â”‚
        â–¼
[2] Bass Isolation      â€” Demucs htdemucs Â· U-Net + Transformer inference (~3-5 min)
        â”‚
        â–¼
[3] MIDI Conversion     â€” Basic Pitch predict_and_save() Â· CNN inference
        â”‚
        â–¼
[4] Base64 Encode       â€” MIDI bytes â†’ JSON response â†’ browser download
        â”‚
        â–¼
[5] Cleanup             â€” /temp directory wiped regardless of outcome
```

### Neural Network Visualization

During processing, the frontend renders a **live canvas** showing the architecture of each neural network as it runs:

- **Demucs (progress 10â€“84%):** Shows the U-Net encoder layers compressing the signal, the Transformer attention block processing temporal dependencies, and the decoder layers reconstructing the isolated bass stem â€” with U-Net skip connections (dashed lines) bridging encoder to decoder.
- **Basic Pitch (progress 85â€“100%):** Shows the CNN pipeline with convolutional layers extracting spectral features, a dense layer, and three branching outputs: **Pitch**, **Onset**, and **Notes**.

Animated **data particles** flow through active connections in real-time, synchronized with the SSE progress events from the backend.

---

## ğŸ¯ Features

### ğŸµ Audio Processing
- **BPM Detection** â€” Librosa beat_track() for tempo extraction
- **Bass Stem Isolation** â€” Demucs `htdemucs` neural network source separation
- **Audio â†’ MIDI** â€” Spotify's Basic Pitch CNN with ICASSP 2022 model
- Supports **MP3, WAV, FLAC, OGG** Â· Max 100MB

### ğŸ–¥ï¸ Frontend
- **Neural network visualization** â€” live canvas rendering of Demucs U-Net and Basic Pitch CNN architectures with animated data flow
- **Drag & drop** file upload with visual hover feedback
- **Real-time SSE progress** â€” Server-Sent Events streaming progress from backend
- **Processing log** with timestamped pipeline steps
- **Info notification on load** â€” warns about CPU processing time
- **Pipeline step indicator** â€” Upload â†’ Process â†’ Download
- **Result card** with detected BPM and one-click MIDI download
- **404 page** with glitch design for invalid routes
- **Responsive footer** with GitHub, LinkedIn, Instagram, Portfolio, email & phone
- Dark theme with acid-green accent color system

### ğŸ”’ Backend Architecture
- **Background job architecture** â€” `POST /api/process` returns `job_id` instantly, processing runs in background thread
- **SSE progress streaming** â€” `GET /api/progress/{job_id}` streams real-time events via Server-Sent Events
- **Result retrieval** â€” `GET /api/result/{job_id}` returns final MIDI + BPM after processing completes
- **Service Pattern** â€” isolated `BassExtractor` class handles the full AI pipeline
- **Non-blocking** â€” `asyncio.to_thread()` keeps FastAPI responsive during long Demucs jobs
- **Thread-safe job store** â€” uses `loop.call_soon_threadsafe()` for cross-thread event pushing
- **Bulletproof cleanup** â€” `try/finally` guarantees temp files are always removed
- **UUID-based paths** â€” prevents path traversal and race conditions
- **Base64 transfer** â€” MIDI returned encoded in JSON, never as static files
- **Health check** â€” `GET /health` for container startup probing
- **CORS configured** â€” Vercel origin whitelisted

---

## ğŸ› ï¸ Tech Stack

### Backend (Python)
| Technology | Version | Purpose |
|---|---|---|
| FastAPI | 0.111.0 | Async REST API with OpenAPI docs |
| Uvicorn | 0.29.0 | ASGI server |
| PyTorch | 2.1.2 (CPU) | ML engine for Demucs |
| TensorFlow | 2.15 | ML engine for Basic Pitch |
| Demucs | 4.0.1 | Neural source separation (Meta AI) |
| Basic Pitch | 0.3.3 | Audio-to-MIDI conversion (Spotify) |
| Librosa | 0.10.2 | Audio analysis & BPM detection |
| NumPy | <2.0 | Numerical operations |
| SoundFile | 0.12.1 | Audio file I/O |

### Frontend (JavaScript)
| Technology | Purpose |
|---|---|
| React 18 | Reactive UI with hooks |
| Vite 4 | Fast dev server & bundler |
| Tailwind CSS 3 | Utility-first styling |
| Canvas API | Neural network architecture visualization |
| EventSource API | SSE streaming for real-time progress |
| Lucide React | SVG icon library |

### DevOps & Infrastructure
| Technology | Purpose |
|---|---|
| Docker | Containerized backend (layer-optimized) |
| Hugging Face Spaces | Backend hosting (Docker SDK, CPU, 16GB RAM) |
| Vercel | Frontend CDN with auto-deploy from GitHub |
| Git | Multi-remote (GitHub + HF Spaces) |
| ffmpeg | System audio codec support |

---

## ğŸ“ Project Structure

```
dumu/
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ App.jsx               # Main UI â€” state machine + all views
â”‚   â”‚   â”œâ”€â”€ main.jsx              # React entry point
â”‚   â”‚   â”œâ”€â”€ index.css             # Tailwind base styles
â”‚   â”‚   â”œâ”€â”€ styles/
â”‚   â”‚   â”‚   â””â”€â”€ global.css        # Design tokens, animations, keyframes
â”‚   â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”‚   â””â”€â”€ bassApi.js        # startJob() + getResult() + ApiError
â”‚   â”‚   â”œâ”€â”€ hooks/
â”‚   â”‚   â”‚   â”œâ”€â”€ useExtraction.js  # FSM hook: idle â†’ processing â†’ done/error
â”‚   â”‚   â”‚   â””â”€â”€ useProgressStream.js  # SSE EventSource hook
â”‚   â”‚   â””â”€â”€ components/
â”‚   â”‚       â”œâ”€â”€ NeuralCanvas.jsx  # Live neural network architecture visualization
â”‚   â”‚       â”œâ”€â”€ DropZone.jsx      # Drag & drop upload
â”‚   â”‚       â”œâ”€â”€ LogConsole.jsx    # Processing log with auto-scroll
â”‚   â”‚       â”œâ”€â”€ ResultCard.jsx    # BPM display + MIDI download
â”‚   â”‚       â””â”€â”€ NotFound.jsx      # 404 page
â”‚   â”œâ”€â”€ vercel.json               # SPA rewrites
â”‚   â”œâ”€â”€ vite.config.js            # Dev proxy + build config
â”‚   â””â”€â”€ tailwind.config.js        # Custom theme (acid colors, fonts)
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py                   # FastAPI app + CORS + /health
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ routes.py             # /process, /progress/{id}, /result/{id}
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ audio_engine.py       # BassExtractor â€” full AI pipeline
â”‚   â”‚   â””â”€â”€ job_store.py          # Thread-safe in-memory job registry
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ hf-space/                     # HF Spaces deployment (own git repo)
â”‚   â”œâ”€â”€ Dockerfile                # Docker SDK, port 7860, non-root
â”‚   â”œâ”€â”€ README.md                 # HF Spaces YAML metadata
â”‚   â”œâ”€â”€ main.py
â”‚   â”œâ”€â”€ api/
â”‚   â”‚   â””â”€â”€ routes.py
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ audio_engine.py
â”‚   â”‚   â””â”€â”€ job_store.py
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile                    # Root Dockerfile (backend build)
â””â”€â”€ README.md
```

---

## ğŸš€ Deployment

### Production
| Service | Platform | URL |
|---|---|---|
| Frontend (Auto) | Vercel | [dumu.vercel.app](https://dumu.vercel.app) |
| Frontend (Manual) | Surge | [dumu.surge.sh](https://dumu.surge.sh) |
| Backend | Hugging Face Spaces | [julian4deep-bass-trap-ai.hf.space](https://julian4deep-bass-trap-ai.hf.space) |

### API Endpoints
| Method | Path | Description |
|---|---|---|
| `POST` | `/api/process` | Upload audio â†’ returns `{ job_id }` immediately |
| `GET` | `/api/progress/{job_id}` | SSE stream of `{ progress, message }` events |
| `GET` | `/api/result/{job_id}` | Final result: `{ bpm, midi_b64, filename }` |
| `GET` | `/health` | Health check: `{ status: "ok" }` |

### Environment Variables

**Vercel (Frontend):**
| Variable | Value |
|---|---|
| `VITE_API_URL` | `https://julian4deep-bass-trap-ai.hf.space` |

### Local Development

#### Prerequisites
- **Node.js 18+** Â· **Python 3.11+** Â· **ffmpeg**

```bash
# Install ffmpeg
# macOS: brew install ffmpeg
# Ubuntu: sudo apt install ffmpeg
# Windows: winget install ffmpeg
```

#### 1. Backend
```bash
cd backend
pip install -r requirements.txt
uvicorn main:app --reload
# API at http://localhost:8000 Â· Docs at http://localhost:8000/docs
```

#### 2. Frontend
```bash
cd frontend
npm install --legacy-peer-deps
npm run dev
# UI at http://localhost:5173

# To manually deploy frontend updates to Surge (dumu.surge.sh):
npm run deploy
```

#### 3. Docker
```bash
docker build -t dumu .
docker run -p 7860:7860 dumu
```

---

## ğŸ—ºï¸ Roadmap

### Phase 1 â€” Core AI Pipeline âœ… v1.0.0
- [x] Audio upload with type & size validation
- [x] BPM detection via Librosa
- [x] Bass isolation via Demucs neural network
- [x] Audio-to-MIDI via Basic Pitch CNN
- [x] Base64 MIDI response + one-click download
- [x] Processing log UI

### Phase 1.1 â€” Production Deploy âœ… v1.1.0
- [x] Dockerized backend (CPU-only PyTorch)
- [x] Deployed to Hugging Face Spaces
- [x] Frontend on Vercel CDN
- [x] Non-blocking async processing
- [x] Non-root container security

### Phase 1.2 â€” UX & Stability âœ… v1.2.0
- [x] Animated progress bar (0â€“100%)
- [x] Info notification about CPU processing time
- [x] Professional footer with social links & contact
- [x] 404 page with glitch design
- [x] Fixed Basic Pitch 0.3.x API compatibility
- [x] Fixed diffq dependency for Demucs
- [x] Environment variable alignment
- [x] Increased server timeout to 300s

### Phase 1.3 â€” Neural Network Visualization & 503 Fix âœ… v1.3.0
- [x] Live neural network architecture canvas (Demucs U-Net + Basic Pitch CNN)
- [x] Animated data particle flow synced to SSE progress
- [x] Background job architecture with SSE streaming
- [x] Fixed 503 errors â€” proper Python package structure
- [x] Switched to `htdemucs` model (CPU-friendly, ~1.5 GB RAM)
- [x] Forced `--device cpu` with `-j 1` and 10-min timeout
- [x] Added `/health` endpoint for HF Spaces container probing
- [x] Removed Railway/nixpacks artifacts â€” HF Spaces Docker only

### Phase 2 â€” Enhanced Audio & Visualization ğŸ“… v2.0.0
- [ ] **Waveform visualization** â€” render input audio waveform alongside the neural canvas using Web Audio API
- [ ] **MIDI preview player** â€” play extracted MIDI directly in the browser using Tone.js synthesizer
- [ ] **Spectrogram view** â€” FFT-powered spectrogram of the isolated bass stem (before/after)
- [ ] **Adjustable Basic Pitch parameters** â€” let users control onset threshold, minimum note length, and pitch confidence
- [ ] **Multiple stem export** â€” extract drums, vocals, bass, and other stems simultaneously using Demucs multi-stem mode
- [ ] **WebSocket progress** â€” upgrade from SSE to WebSocket for bidirectional communication and cancellation support

### Phase 3 â€” Advanced AI & Music Intelligence ğŸ“… v3.0.0
- [ ] **Key detection** â€” identify musical key and scale using Krumhansl-Schmuckler algorithm + ML classifier
- [ ] **Chord progression analysis** â€” detect chord changes from the harmonic content of the audio
- [ ] **MIDI quantization & cleanup** â€” snap notes to grid, remove ghost notes, apply velocity curves
- [ ] **Smart tempo mapping** â€” detect tempo changes and rubato in live recordings
- [ ] **Custom Demucs fine-tuning** â€” fine-tune htdemucs on bass-heavy genres (funk, jazz, metal) for better isolation
- [ ] **Multi-model ensemble** â€” combine multiple separation models and select best output via perceptual quality metric

### Phase 4 â€” Architecture & Scale ğŸ“… v4.0.0
- [ ] **Redis job queue** â€” replace in-memory job store with Redis for persistence across container restarts
- [ ] **Celery workers** â€” distribute processing across multiple containers with task routing
- [ ] **GPU inference** â€” add GPU-accelerated Demucs inference on HF Spaces Pro (A10G) for 10x speedup
- [ ] **Model caching with HF Hub** â€” download models once to persistent volume, avoid cold-start delays
- [ ] **Rate limiting & auth** â€” JWT authentication with rate limits per user tier
- [ ] **S3/GCS output storage** â€” store processed files in object storage with signed URLs and TTL
- [ ] **Batch processing API** â€” upload multiple tracks in a single request with parallel pipeline execution

### Phase 5 â€” Platform & ML Research ğŸ“… v5.0.0
- [ ] **User accounts & history** â€” PostgreSQL-backed user system with processing history and saved results
- [ ] **DAW plugin (VST3/AU)** â€” native plugin that sends audio to the Dumu API and receives MIDI in real-time
- [ ] **Custom neural network training** â€” allow users to upload labeled training data and fine-tune personal separation models
- [ ] **Real-time streaming separation** â€” chunk audio into windows and process with streaming Demucs for live bass extraction
- [ ] **Hybrid edge/cloud inference** â€” run lightweight ONNX models on-device for preview, full models on cloud for final output
- [ ] **Music generation from bass lines** â€” use extracted MIDI + key/chord analysis to generate drum patterns and harmonies with transformers
- [ ] **A/B model comparison dashboard** â€” test different Demucs variants side-by-side with perceptual quality metrics (SDR, SIR, SAR)

---

## âš ï¸ Performance Notes

> Processing on **CPU takes 3â€“7+ minutes** for full-length tracks. This is expected behavior â€” Demucs runs a deep neural network on every audio frame. For faster results, use shorter audio clips (< 30s) or MP3 files instead of WAV.

---

## ğŸ‘¨â€ğŸ’» Author

**Julian Javier Soto**  
Senior Software Engineer Â· AI & Audio Processing  
Specialized in Python, TypeScript, React, Machine Learning & Cloud Deployment

[![GitHub](https://img.shields.io/badge/GitHub-juliandeveloper05-181717?style=flat-square&logo=github)](https://github.com/juliandeveloper05)
[![LinkedIn](https://img.shields.io/badge/LinkedIn-Julian_Soto-0A66C2?style=flat-square&logo=linkedin)](https://www.linkedin.com/in/full-stack-julian-soto/)
[![Portfolio](https://img.shields.io/badge/Portfolio-juliansoto-000?style=flat-square&logo=vercel)](https://juliansoto-portfolio.vercel.app/es)
[![Instagram](https://img.shields.io/badge/Instagram-palee__0x71-E4405F?style=flat-square&logo=instagram)](https://www.instagram.com/palee_0x71)

ğŸ“§ **Email:** juliansoto.dev@gmail.com  
ğŸ“± **WhatsApp:** +54 9 11 3066-6369

---

## ğŸ“„ License

This project is licensed under the **MIT License** â€” see the [LICENSE](LICENSE) file for details.

---

**Dumu v1.3.0** â€” Made with â¤ï¸ and ğŸ§  by Julian Javier Soto Â· Â© 2026